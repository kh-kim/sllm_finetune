{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1694066393964,"user":{"displayName":"KI HYUN KIM","userId":"09674178224796984612"},"user_tz":-540},"id":"a_n1tyaYICHf","outputId":"c5f3988d-c450-40e6-d479-d8e5fd8d5ba4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Sep  7 05:59:53 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    46W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4722,"status":"ok","timestamp":1694066398683,"user":{"displayName":"KI HYUN KIM","userId":"09674178224796984612"},"user_tz":-540},"id":"NFBax8aAGHAW","outputId":"86f33493-2d3d-48bb-b2ad-a0b0f496fc66"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.1)\n","Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.5.0)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.41.1)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.22.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.0.1+cu118)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft) (16.0.6)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"]}],"source":["!pip install transformers peft bitsandbytes accelerate datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5127,"status":"ok","timestamp":1694066403804,"user":{"displayName":"KI HYUN KIM","userId":"09674178224796984612"},"user_tz":-540},"id":"KPLO4nFkIU3_","outputId":"75c5c02d-7b21-4a56-9985-b0ca051df8ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.10)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.34)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.30.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"]}],"source":["!pip install wandb"]},{"cell_type":"markdown","metadata":{},"source":["Get you API_KEY from https://wandb.ai/quickstart"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1632,"status":"ok","timestamp":1694066405431,"user":{"displayName":"KI HYUN KIM","userId":"09674178224796984612"},"user_tz":-540},"id":"anaUQbXBIXj0","outputId":"f31c9602-61bd-4df6-c8f3-87f332a560c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!wandb login YOUR_API_KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9g9B-IL5JZgr"},"outputs":[],"source":["!cp ./drive/MyDrive/lecture_workspace/finetune.py ./\n","\n","!mkdir -p data\n","!cp ./drive/MyDrive/lecture_workspace/aug.jsonl ./data/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1140424,"status":"ok","timestamp":1694079566723,"user":{"displayName":"KI HYUN KIM","userId":"09674178224796984612"},"user_tz":-540},"id":"68UADfpeIpzE","outputId":"6844d1ef-e021-4bd9-c52b-577268ab28d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-09-07 06:01:57.038636: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkimkihyun\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230907_060201-s1s9ybzt\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcelestial-cosmos-13\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/kimkihyun/Meeting-Log-Summ\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/kimkihyun/Meeting-Log-Summ/runs/s1s9ybzt\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n","Sample data:\n","### 회의록:\n","감사원장 양건] \"예.\"\n","서영교 위원] \"그때 청와대에 여러 사람이 파견돼 있다 보면 감사원이 감사원으로서 제 기능을 하기 어렵다 그리고 사실 검찰로부터 내곡동 사저 감사가 필요하다는 이야기도 했었음에도 불구하고 감사원에서 하지 않고 있고 이러다보니 그리고 당시에 대통령실에 여러 차례 업무보고를 하러 가고 이것이 살짝 정치적으로 볼 때는 대통령실과 연계가 있는 것 아니냐 이런 오해도 불러일으킬 수 있으면서 감사원 직원들을 되도록이면 파견하는 것을 제자리로 복귀시키는 게 어떻겠느냐 이런 질의했었습니다. 그 사이에 변화가 있었습니까?\"\n","감사원장 양건] \"당장 지금 변화는 없습니다마는 지금 지적하신 문제는 과거에도 더러 지적되었던 문제이고 저희도 내부적으로 그 문제를 검토한 바도 있습니다. 그래서 앞으로 그 파견 문제에 관해서 한번 전반적으로 필요성과 이런 걸 재검토해 보겠습니다.\"\n","서영교 위원] \"우선 민정수석실에만 4명이 파견되어 있습니다. 전체 9명 중에 4명이 파견돼 있는데 실제로 민정수석실이 측근비리라든지 문제점들을 제대로 감시해서 문제가 일어나지 않게 해야 되는데 민정수석실이 사실은 손을 놓고 있는지 대통령 측근들의 비리가 엄청나게 벌어지고 있음에도 불구하고 손을 놓고 있었어요. 이런 데 감사원에서 4명이나 가 있으면서 제대로 감사가 되고 있는지 문제가 큽니다. 지난번에도 문제 제기를 했고 이번에 제대로 돼 있는지 다시 한번 검토하는데 별로 변화가 없습니다. 바로 다음 문제 제기 때는 이 부분에 변화가 있을 수 있게 준비해 주셨으면 한다는 제기를 하고 싶습니다. 다음은 결산과 관련해서 질의하도록 하겠습니다. 감사원의 특수활동비에 관해서는 매년 매번 법사위에서 지적되고 제기되고 있는 내용입니다. 이 법사위에 작년에도 우윤근 의원이 특수활동비를 공개해야 한다라고 했습니다. 특수활동비 자료 제출하실 용의 없으십니까?\"\n","\n","### 회의 참석자:\n","감사원장 양건\n","서영교 위원\n","\n","### 주장하는 사람:\n","서영교 위원\n","\n","### 주장과 근거:\n","주장: 감사원이 감사원으로서 제 기능을 하기 어렵고, 검찰로부터 필요한 사저 감사를 하지 않으며, 대통령실과 연계가 있다는 오해가 있기 때문에 감사원 직원들을 되도록이면 파견에서 복귀시켜야 한다.\n","근거: 청와대에 여러 사람이 파견되어있고, 감사원이 제 기능을 하기 힘들고, 검찰로부터 감사 요청이 있었으며, 대통령실과의 연계 여부에 대한 오해가 발생할 수 있다.\n","\n","### 요약:\n","서영교 위원은 감사원이 감사 업무를 충실히 하지 못하고 대통령실과의 연관성에 오해가 생기는 문제를 지적하고, 감사원 직원들의 파견을 복귀시켜야 한다는 주장을 했다. 이 주장은 청와대에 파견되어 있는 사람들의 존재, 감사원의 업무수행능력, 검찰로부터의 지적, 대통령실과의 연계 오해 등을 근거로 하고 있다.<|sep|><|endoftext|>\n","Train dataset size: 7798\n","Eval dataset size: 200\n","Downloading (…)okenizer_config.json: 100% 174/174 [00:00<00:00, 564kB/s]\n","Downloading (…)/main/tokenizer.json: 100% 1.65M/1.65M [00:00<00:00, 3.35MB/s]\n","Downloading (…)cial_tokens_map.json: 100% 204/204 [00:00<00:00, 701kB/s]\n","Map: 100% 7798/7798 [00:04<00:00, 1842.82 examples/s]\n","Map: 100% 200/200 [00:00<00:00, 1998.12 examples/s]\n","Downloading (…)lve/main/config.json: 100% 678/678 [00:00<00:00, 1.73MB/s]\n","Downloading (…)fetensors.index.json: 100% 52.5k/52.5k [00:00<00:00, 96.6MB/s]\n","Downloading shards:   0% 0/28 [00:00<?, ?it/s]\n","Downloading (…)of-00028.safetensors:   0% 0.00/946M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   4% 41.9M/946M [00:00<00:02, 387MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  11% 105M/946M [00:00<00:01, 483MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  18% 168M/946M [00:00<00:01, 515MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  24% 231M/946M [00:00<00:01, 527MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  31% 294M/946M [00:00<00:01, 530MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  38% 357M/946M [00:00<00:01, 534MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  44% 419M/946M [00:00<00:00, 536MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  51% 482M/946M [00:00<00:00, 528MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  58% 545M/946M [00:01<00:00, 530MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  64% 608M/946M [00:01<00:00, 532MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  71% 671M/946M [00:01<00:00, 531MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  78% 734M/946M [00:01<00:00, 535MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  84% 797M/946M [00:01<00:00, 536MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  91% 860M/946M [00:01<00:00, 537MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 946M/946M [00:01<00:00, 523MB/s]\n","Downloading shards:   4% 1/28 [00:02<00:58,  2.15s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/843M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   5% 41.9M/843M [00:00<00:01, 413MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  11% 94.4M/843M [00:00<00:01, 412MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  16% 136M/843M [00:00<00:01, 398MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  21% 178M/843M [00:00<00:01, 387MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  26% 220M/843M [00:00<00:01, 373MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  31% 262M/843M [00:00<00:01, 373MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  36% 304M/843M [00:00<00:01, 373MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  41% 346M/843M [00:00<00:01, 370MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  46% 388M/843M [00:01<00:01, 357MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  51% 430M/843M [00:01<00:01, 355MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  56% 472M/843M [00:01<00:01, 354MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  61% 514M/843M [00:01<00:01, 328MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  66% 556M/843M [00:01<00:00, 321MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  71% 598M/843M [00:01<00:00, 305MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  76% 640M/843M [00:01<00:00, 315MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  81% 682M/843M [00:01<00:00, 321MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  86% 724M/843M [00:02<00:00, 329MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  91% 765M/843M [00:02<00:00, 342MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  96% 807M/843M [00:02<00:00, 351MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 843M/843M [00:02<00:00, 348MB/s]\n","Downloading shards:   7% 2/28 [00:04<01:04,  2.47s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/843M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   6% 52.4M/843M [00:00<00:01, 433MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  12% 105M/843M [00:00<00:01, 469MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  19% 157M/843M [00:00<00:01, 478MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  25% 210M/843M [00:00<00:01, 484MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  31% 262M/843M [00:00<00:01, 487MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  37% 315M/843M [00:00<00:01, 488MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  44% 367M/843M [00:00<00:00, 476MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  50% 419M/843M [00:00<00:00, 481MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  56% 472M/843M [00:00<00:00, 485MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  62% 524M/843M [00:01<00:00, 485MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  68% 577M/843M [00:01<00:00, 487MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  76% 640M/843M [00:01<00:00, 502MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  83% 703M/843M [00:01<00:00, 508MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  90% 755M/843M [00:01<00:00, 495MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 843M/843M [00:01<00:00, 487MB/s]\n","Downloading shards:  11% 3/28 [00:06<00:56,  2.26s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/1.00G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   5% 52.4M/1.00G [00:00<00:02, 449MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  10% 105M/1.00G [00:00<00:01, 460MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  16% 157M/1.00G [00:00<00:02, 408MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  20% 199M/1.00G [00:00<00:02, 362MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  24% 241M/1.00G [00:00<00:02, 341MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  28% 283M/1.00G [00:00<00:02, 323MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  32% 325M/1.00G [00:00<00:02, 302MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  35% 357M/1.00G [00:01<00:02, 291MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  39% 388M/1.00G [00:01<00:02, 287MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  42% 419M/1.00G [00:01<00:01, 293MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  45% 451M/1.00G [00:01<00:01, 291MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  48% 482M/1.00G [00:01<00:01, 289MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  51% 514M/1.00G [00:01<00:01, 280MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  54% 545M/1.00G [00:01<00:01, 275MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  59% 598M/1.00G [00:01<00:01, 329MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  66% 661M/1.00G [00:01<00:00, 391MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  70% 703M/1.00G [00:02<00:00, 397MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  74% 744M/1.00G [00:02<00:00, 365MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  78% 786M/1.00G [00:02<00:00, 368MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  82% 828M/1.00G [00:02<00:00, 356MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  87% 870M/1.00G [00:02<00:00, 365MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  91% 912M/1.00G [00:02<00:00, 362MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  95% 954M/1.00G [00:02<00:00, 350MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 1.00G/1.00G [00:02<00:00, 336MB/s]\n","Downloading shards:  14% 4/28 [00:10<01:03,  2.65s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/896M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   6% 52.4M/896M [00:00<00:01, 453MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  13% 115M/896M [00:00<00:01, 504MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  20% 178M/896M [00:00<00:01, 519MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  27% 241M/896M [00:00<00:01, 523MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  33% 294M/896M [00:00<00:01, 482MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  39% 346M/896M [00:00<00:01, 419MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  44% 398M/896M [00:01<00:01, 317MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  50% 451M/896M [00:01<00:01, 350MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  56% 503M/896M [00:01<00:01, 388MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  62% 556M/896M [00:01<00:00, 382MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  67% 598M/896M [00:01<00:00, 371MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  71% 640M/896M [00:01<00:00, 362MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  76% 682M/896M [00:01<00:00, 363MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  82% 734M/896M [00:01<00:00, 395MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  88% 786M/896M [00:01<00:00, 424MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  94% 839M/896M [00:02<00:00, 438MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 896M/896M [00:02<00:00, 412MB/s]\n","Downloading shards:  18% 5/28 [00:12<00:59,  2.57s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/1.00G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   4% 41.9M/1.00G [00:00<00:02, 409MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   8% 83.9M/1.00G [00:00<00:02, 391MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  13% 126M/1.00G [00:00<00:02, 398MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  17% 168M/1.00G [00:00<00:02, 392MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  22% 220M/1.00G [00:00<00:01, 403MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  26% 262M/1.00G [00:00<00:01, 398MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  31% 315M/1.00G [00:00<00:01, 420MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  37% 367M/1.00G [00:00<00:01, 437MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  42% 419M/1.00G [00:00<00:01, 451MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  47% 472M/1.00G [00:01<00:01, 460MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  53% 535M/1.00G [00:01<00:00, 486MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  59% 598M/1.00G [00:01<00:00, 504MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  66% 661M/1.00G [00:01<00:00, 514MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  72% 724M/1.00G [00:01<00:00, 521MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  77% 776M/1.00G [00:01<00:00, 466MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  82% 828M/1.00G [00:01<00:00, 385MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  87% 870M/1.00G [00:02<00:00, 354MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  91% 912M/1.00G [00:02<00:00, 334MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  95% 954M/1.00G [00:02<00:00, 332MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 1.00G/1.00G [00:02<00:00, 397MB/s]\n","Downloading shards:  21% 6/28 [00:15<00:59,  2.70s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/896M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   6% 52.4M/896M [00:00<00:01, 475MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  13% 115M/896M [00:00<00:01, 514MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  19% 168M/896M [00:00<00:01, 476MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  25% 220M/896M [00:00<00:01, 397MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  29% 262M/896M [00:00<00:01, 383MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  34% 304M/896M [00:00<00:01, 345MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  39% 346M/896M [00:00<00:01, 359MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  43% 388M/896M [00:01<00:01, 346MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  48% 430M/896M [00:01<00:01, 346MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  53% 472M/896M [00:01<00:01, 344MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  57% 514M/896M [00:01<00:01, 337MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  62% 556M/896M [00:01<00:01, 322MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  68% 608M/896M [00:01<00:00, 363MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  73% 650M/896M [00:01<00:00, 368MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  78% 703M/896M [00:01<00:00, 389MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  84% 755M/896M [00:01<00:00, 414MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  90% 807M/896M [00:02<00:00, 422MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 896M/896M [00:02<00:00, 389MB/s]\n","Downloading shards:  25% 7/28 [00:18<00:55,  2.66s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/1.00G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   2% 21.0M/1.00G [00:00<00:06, 154MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   5% 52.4M/1.00G [00:00<00:04, 211MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   9% 94.4M/1.00G [00:00<00:03, 287MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  15% 147M/1.00G [00:00<00:02, 367MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  20% 199M/1.00G [00:00<00:01, 414MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  25% 252M/1.00G [00:00<00:01, 444MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  30% 304M/1.00G [00:00<00:01, 464MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  35% 357M/1.00G [00:00<00:01, 478MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  41% 409M/1.00G [00:00<00:01, 488MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  46% 461M/1.00G [00:01<00:01, 491MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  51% 514M/1.00G [00:01<00:00, 494MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  56% 566M/1.00G [00:01<00:00, 497MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  62% 619M/1.00G [00:01<00:00, 498MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  67% 671M/1.00G [00:01<00:00, 501MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  72% 724M/1.00G [00:01<00:00, 423MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  77% 776M/1.00G [00:01<00:00, 364MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  81% 818M/1.00G [00:02<00:00, 337MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  86% 860M/1.00G [00:02<00:00, 321MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  90% 902M/1.00G [00:02<00:00, 309MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  94% 944M/1.00G [00:02<00:00, 300MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 1.00G/1.00G [00:02<00:00, 370MB/s]\n","Downloading shards:  29% 8/28 [00:21<00:55,  2.76s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/896M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   6% 52.4M/896M [00:00<00:01, 458MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  12% 105M/896M [00:00<00:01, 438MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  18% 157M/896M [00:00<00:01, 440MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  23% 210M/896M [00:00<00:01, 380MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  28% 252M/896M [00:00<00:01, 368MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  33% 294M/896M [00:00<00:01, 372MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  37% 336M/896M [00:00<00:01, 366MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  42% 377M/896M [00:01<00:01, 328MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  47% 419M/896M [00:01<00:01, 334MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  52% 461M/896M [00:01<00:01, 352MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  56% 503M/896M [00:01<00:01, 359MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  62% 556M/896M [00:01<00:00, 386MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  67% 598M/896M [00:01<00:00, 389MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  71% 640M/896M [00:01<00:00, 373MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  76% 682M/896M [00:01<00:00, 371MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  81% 724M/896M [00:01<00:00, 348MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  85% 765M/896M [00:02<00:00, 337MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  90% 807M/896M [00:02<00:00, 317MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  95% 849M/896M [00:02<00:00, 312MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 896M/896M [00:02<00:00, 350MB/s]\n","Downloading shards:  32% 9/28 [00:23<00:52,  2.78s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/1.00G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   4% 41.9M/1.00G [00:00<00:02, 371MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   9% 94.4M/1.00G [00:00<00:02, 414MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  15% 147M/1.00G [00:00<00:02, 417MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  19% 189M/1.00G [00:00<00:02, 408MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  23% 231M/1.00G [00:00<00:01, 402MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  27% 273M/1.00G [00:00<00:01, 389MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  31% 315M/1.00G [00:00<00:01, 377MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  35% 357M/1.00G [00:00<00:01, 354MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  40% 398M/1.00G [00:01<00:01, 347MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  44% 440M/1.00G [00:01<00:01, 347MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  48% 482M/1.00G [00:01<00:01, 330MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  52% 524M/1.00G [00:01<00:01, 323MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  56% 566M/1.00G [00:01<00:01, 310MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  61% 608M/1.00G [00:01<00:01, 308MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  64% 640M/1.00G [00:01<00:01, 303MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  67% 671M/1.00G [00:01<00:01, 299MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  71% 713M/1.00G [00:02<00:00, 297MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  74% 744M/1.00G [00:02<00:00, 292MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  77% 776M/1.00G [00:02<00:00, 288MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  81% 818M/1.00G [00:02<00:00, 287MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  85% 849M/1.00G [00:02<00:00, 283MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  88% 881M/1.00G [00:02<00:00, 279MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  91% 912M/1.00G [00:02<00:00, 286MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  94% 944M/1.00G [00:02<00:00, 289MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 1.00G/1.00G [00:03<00:00, 320MB/s]\n","Downloading shards:  36% 10/28 [00:27<00:53,  2.97s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/896M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   5% 41.9M/896M [00:00<00:02, 417MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  11% 94.4M/896M [00:00<00:01, 459MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  16% 147M/896M [00:00<00:01, 474MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  22% 199M/896M [00:00<00:01, 483MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  28% 252M/896M [00:00<00:01, 487MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  34% 304M/896M [00:00<00:01, 485MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  40% 357M/896M [00:00<00:01, 485MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  46% 409M/896M [00:00<00:01, 483MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  52% 461M/896M [00:01<00:01, 312MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  57% 514M/896M [00:01<00:01, 346MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  63% 566M/896M [00:01<00:00, 382MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  69% 619M/896M [00:01<00:00, 403MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  75% 671M/896M [00:01<00:00, 416MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  81% 724M/896M [00:01<00:00, 438MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  87% 776M/896M [00:01<00:00, 447MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  92% 828M/896M [00:01<00:00, 437MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 896M/896M [00:02<00:00, 426MB/s]\n","Downloading shards:  39% 11/28 [00:29<00:47,  2.79s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/1.00G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   4% 41.9M/1.00G [00:00<00:02, 399MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   9% 94.4M/1.00G [00:00<00:02, 430MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  15% 147M/1.00G [00:00<00:01, 444MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  20% 199M/1.00G [00:00<00:01, 449MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  25% 252M/1.00G [00:00<00:01, 453MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  30% 304M/1.00G [00:00<00:01, 455MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  35% 357M/1.00G [00:00<00:01, 454MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  41% 409M/1.00G [00:00<00:01, 454MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  46% 461M/1.00G [00:01<00:01, 453MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  51% 514M/1.00G [00:01<00:01, 459MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  56% 566M/1.00G [00:01<00:00, 460MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  62% 619M/1.00G [00:01<00:00, 456MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  67% 671M/1.00G [00:01<00:00, 431MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  72% 724M/1.00G [00:01<00:00, 440MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  77% 776M/1.00G [00:01<00:00, 434MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  82% 828M/1.00G [00:01<00:00, 442MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  88% 881M/1.00G [00:01<00:00, 442MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  93% 933M/1.00G [00:02<00:00, 443MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 1.00G/1.00G [00:02<00:00, 444MB/s]\n","Downloading shards:  43% 12/28 [00:32<00:43,  2.71s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/896M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   6% 52.4M/896M [00:00<00:01, 439MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  12% 105M/896M [00:00<00:01, 471MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  18% 157M/896M [00:00<00:01, 483MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  23% 210M/896M [00:00<00:01, 490MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  29% 262M/896M [00:00<00:01, 495MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  35% 315M/896M [00:00<00:01, 493MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  41% 367M/896M [00:00<00:01, 496MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  47% 419M/896M [00:00<00:00, 498MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  53% 472M/896M [00:00<00:00, 499MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  59% 524M/896M [00:01<00:00, 489MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  64% 577M/896M [00:01<00:00, 491MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  70% 629M/896M [00:01<00:00, 493MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  76% 682M/896M [00:01<00:00, 494MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  82% 734M/896M [00:01<00:00, 496MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  88% 786M/896M [00:01<00:00, 496MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  94% 839M/896M [00:01<00:00, 498MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 896M/896M [00:02<00:00, 443MB/s]\n","Downloading shards:  46% 13/28 [00:34<00:38,  2.58s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/1.00G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   4% 41.9M/1.00G [00:00<00:02, 419MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   9% 94.4M/1.00G [00:00<00:01, 462MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  15% 147M/1.00G [00:00<00:01, 479MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  20% 199M/1.00G [00:00<00:01, 440MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  25% 252M/1.00G [00:00<00:02, 322MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  29% 294M/1.00G [00:00<00:02, 279MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  32% 325M/1.00G [00:01<00:02, 249MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  35% 357M/1.00G [00:01<00:02, 217MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  39% 388M/1.00G [00:01<00:03, 196MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  42% 419M/1.00G [00:01<00:03, 175MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  44% 440M/1.00G [00:01<00:03, 163MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  46% 461M/1.00G [00:02<00:03, 155MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  49% 493M/1.00G [00:02<00:02, 174MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  53% 535M/1.00G [00:02<00:02, 215MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  58% 587M/1.00G [00:02<00:01, 278MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  64% 640M/1.00G [00:02<00:01, 329MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  69% 692M/1.00G [00:02<00:00, 370MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  74% 744M/1.00G [00:02<00:00, 388MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  79% 797M/1.00G [00:02<00:00, 412MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  85% 849M/1.00G [00:02<00:00, 434MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  90% 902M/1.00G [00:03<00:00, 453MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  95% 954M/1.00G [00:03<00:00, 461MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 1.00G/1.00G [00:03<00:00, 308MB/s]\n","Downloading shards:  50% 14/28 [00:38<00:40,  2.87s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/896M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   6% 52.4M/896M [00:00<00:01, 445MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  12% 105M/896M [00:00<00:01, 452MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  18% 157M/896M [00:00<00:01, 461MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  23% 210M/896M [00:00<00:01, 468MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  29% 262M/896M [00:00<00:01, 471MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  35% 315M/896M [00:00<00:01, 476MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  41% 367M/896M [00:00<00:01, 482MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  47% 419M/896M [00:00<00:00, 483MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  53% 472M/896M [00:01<00:00, 470MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  59% 524M/896M [00:01<00:00, 478MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  64% 577M/896M [00:01<00:00, 487MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  70% 629M/896M [00:01<00:00, 485MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  76% 682M/896M [00:01<00:00, 481MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  82% 734M/896M [00:01<00:00, 478MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  88% 786M/896M [00:01<00:00, 482MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  94% 839M/896M [00:01<00:00, 484MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 896M/896M [00:01<00:00, 475MB/s]\n","Downloading shards:  54% 15/28 [00:40<00:34,  2.65s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/1.00G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   5% 52.4M/1.00G [00:00<00:02, 448MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  10% 105M/1.00G [00:00<00:01, 474MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  16% 157M/1.00G [00:00<00:01, 481MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  21% 210M/1.00G [00:00<00:01, 481MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  26% 262M/1.00G [00:00<00:01, 485MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  31% 315M/1.00G [00:00<00:01, 488MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  37% 367M/1.00G [00:00<00:01, 477MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  42% 419M/1.00G [00:00<00:01, 464MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  47% 472M/1.00G [00:00<00:01, 467MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  52% 524M/1.00G [00:01<00:01, 471MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  57% 577M/1.00G [00:01<00:00, 458MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  63% 629M/1.00G [00:01<00:00, 440MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  68% 682M/1.00G [00:01<00:00, 449MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  74% 744M/1.00G [00:01<00:00, 473MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  79% 797M/1.00G [00:01<00:00, 486MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  85% 849M/1.00G [00:01<00:00, 381MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  89% 891M/1.00G [00:02<00:00, 363MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  93% 933M/1.00G [00:02<00:00, 335MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 1.00G/1.00G [00:02<00:00, 408MB/s]\n","Downloading shards:  57% 16/28 [00:42<00:32,  2.68s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/896M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   5% 41.9M/896M [00:00<00:02, 414MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  11% 94.4M/896M [00:00<00:01, 465MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  16% 147M/896M [00:00<00:01, 486MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  22% 199M/896M [00:00<00:01, 500MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  28% 252M/896M [00:00<00:01, 502MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  34% 304M/896M [00:00<00:01, 432MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  40% 357M/896M [00:00<00:01, 351MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  44% 398M/896M [00:01<00:01, 328MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  49% 440M/896M [00:01<00:01, 306MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  54% 482M/896M [00:01<00:01, 291MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  57% 514M/896M [00:01<00:01, 284MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  61% 545M/896M [00:01<00:01, 279MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  64% 577M/896M [00:01<00:01, 273MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  68% 608M/896M [00:01<00:01, 264MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  71% 640M/896M [00:01<00:01, 249MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  75% 671M/896M [00:02<00:00, 240MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  78% 703M/896M [00:02<00:00, 228MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  82% 734M/896M [00:02<00:00, 214MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  85% 765M/896M [00:02<00:00, 193MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  88% 786M/896M [00:02<00:00, 188MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  90% 807M/896M [00:02<00:00, 173MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  92% 828M/896M [00:03<00:00, 161MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  95% 849M/896M [00:03<00:00, 151MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 896M/896M [00:03<00:00, 259MB/s]\n","Downloading shards:  61% 17/28 [00:46<00:32,  2.99s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/1.00G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   4% 41.9M/1.00G [00:00<00:02, 403MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   9% 94.4M/1.00G [00:00<00:02, 447MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  15% 147M/1.00G [00:00<00:01, 451MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  20% 199M/1.00G [00:00<00:01, 461MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  25% 252M/1.00G [00:00<00:01, 457MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  30% 304M/1.00G [00:00<00:01, 465MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  35% 357M/1.00G [00:00<00:01, 456MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  41% 409M/1.00G [00:00<00:01, 459MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  46% 461M/1.00G [00:01<00:01, 456MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  51% 514M/1.00G [00:01<00:01, 463MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  57% 577M/1.00G [00:01<00:00, 487MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  63% 629M/1.00G [00:01<00:00, 494MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  68% 682M/1.00G [00:01<00:00, 476MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  73% 734M/1.00G [00:01<00:00, 449MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  78% 786M/1.00G [00:01<00:00, 452MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  85% 849M/1.00G [00:01<00:00, 476MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  91% 912M/1.00G [00:01<00:00, 494MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 1.00G/1.00G [00:02<00:00, 472MB/s]\n","Downloading shards:  64% 18/28 [00:48<00:28,  2.81s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/896M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   6% 52.4M/896M [00:00<00:01, 452MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  12% 105M/896M [00:00<00:01, 489MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  18% 157M/896M [00:00<00:01, 499MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  23% 210M/896M [00:00<00:01, 508MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  29% 262M/896M [00:00<00:01, 512MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  35% 315M/896M [00:00<00:01, 433MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  41% 367M/896M [00:00<00:01, 366MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  46% 409M/896M [00:01<00:01, 329MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  50% 451M/896M [00:01<00:01, 296MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  55% 493M/896M [00:01<00:01, 279MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  59% 524M/896M [00:01<00:01, 258MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  62% 556M/896M [00:01<00:01, 244MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  66% 587M/896M [00:01<00:01, 231MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  69% 619M/896M [00:02<00:01, 218MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  73% 650M/896M [00:02<00:01, 207MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  76% 682M/896M [00:02<00:01, 199MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  78% 703M/896M [00:02<00:01, 193MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  81% 724M/896M [00:02<00:00, 186MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  84% 755M/896M [00:02<00:00, 207MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  88% 786M/896M [00:02<00:00, 230MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  92% 828M/896M [00:02<00:00, 260MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 896M/896M [00:03<00:00, 285MB/s]\n","Downloading shards:  68% 19/28 [00:52<00:26,  2.99s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/1.00G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   5% 52.4M/1.00G [00:00<00:02, 464MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  10% 105M/1.00G [00:00<00:01, 491MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  16% 157M/1.00G [00:00<00:01, 503MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  21% 210M/1.00G [00:00<00:01, 505MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  26% 262M/1.00G [00:00<00:01, 506MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  31% 315M/1.00G [00:00<00:01, 508MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  37% 367M/1.00G [00:00<00:01, 509MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  42% 419M/1.00G [00:00<00:01, 512MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  47% 472M/1.00G [00:00<00:01, 511MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  52% 524M/1.00G [00:01<00:00, 513MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  58% 587M/1.00G [00:01<00:00, 517MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  64% 640M/1.00G [00:01<00:00, 511MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  69% 692M/1.00G [00:01<00:00, 514MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  74% 744M/1.00G [00:01<00:00, 427MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  79% 797M/1.00G [00:01<00:00, 319MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  83% 839M/1.00G [00:01<00:00, 289MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  88% 881M/1.00G [00:02<00:00, 278MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  91% 912M/1.00G [00:02<00:00, 265MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  94% 944M/1.00G [00:02<00:00, 268MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  97% 975M/1.00G [00:02<00:00, 265MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 1.00G/1.00G [00:02<00:00, 374MB/s]\n","Downloading shards:  71% 20/28 [00:56<00:27,  3.45s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/896M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   6% 52.4M/896M [00:00<00:01, 453MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  12% 105M/896M [00:00<00:01, 479MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  18% 157M/896M [00:00<00:01, 490MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  23% 210M/896M [00:00<00:01, 493MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  29% 262M/896M [00:00<00:01, 451MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  35% 315M/896M [00:00<00:01, 432MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  42% 377M/896M [00:00<00:01, 462MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  49% 440M/896M [00:00<00:00, 483MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  55% 493M/896M [00:01<00:00, 493MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  61% 545M/896M [00:01<00:00, 500MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  68% 608M/896M [00:01<00:00, 509MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  75% 671M/896M [00:01<00:00, 514MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  81% 724M/896M [00:01<00:00, 514MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  87% 776M/896M [00:01<00:00, 516MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  92% 828M/896M [00:01<00:00, 517MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 896M/896M [00:01<00:00, 494MB/s]\n","Downloading shards:  75% 21/28 [00:59<00:21,  3.04s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/1.00G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   5% 52.4M/1.00G [00:00<00:02, 471MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  10% 105M/1.00G [00:00<00:01, 501MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  16% 157M/1.00G [00:00<00:01, 506MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  22% 220M/1.00G [00:00<00:01, 514MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  28% 283M/1.00G [00:00<00:01, 518MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  34% 346M/1.00G [00:00<00:01, 520MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  40% 398M/1.00G [00:00<00:01, 520MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  45% 451M/1.00G [00:00<00:01, 512MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  50% 503M/1.00G [00:01<00:01, 484MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  55% 556M/1.00G [00:01<00:01, 398MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  61% 608M/1.00G [00:01<00:01, 378MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  65% 650M/1.00G [00:01<00:00, 383MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  69% 692M/1.00G [00:01<00:00, 366MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  74% 744M/1.00G [00:01<00:00, 393MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  79% 797M/1.00G [00:01<00:00, 425MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  86% 860M/1.00G [00:01<00:00, 458MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  91% 912M/1.00G [00:02<00:00, 468MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 1.00G/1.00G [00:02<00:00, 451MB/s]\n","Downloading shards:  79% 22/28 [01:01<00:17,  2.88s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/896M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   4% 31.5M/896M [00:00<00:02, 302MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   8% 73.4M/896M [00:00<00:02, 340MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  13% 115M/896M [00:00<00:02, 340MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  18% 157M/896M [00:00<00:02, 348MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  25% 220M/896M [00:00<00:01, 416MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  32% 283M/896M [00:00<00:01, 459MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  39% 346M/896M [00:00<00:01, 490MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  44% 398M/896M [00:01<00:01, 311MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  50% 451M/896M [00:01<00:01, 348MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  57% 514M/896M [00:01<00:00, 397MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  64% 577M/896M [00:01<00:00, 436MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  71% 640M/896M [00:01<00:00, 466MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  78% 703M/896M [00:01<00:00, 488MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  85% 765M/896M [00:01<00:00, 505MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  92% 828M/896M [00:01<00:00, 519MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 896M/896M [00:02<00:00, 438MB/s]\n","Downloading shards:  82% 23/28 [01:03<00:13,  2.71s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/1.00G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   5% 52.4M/1.00G [00:00<00:02, 473MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  11% 115M/1.00G [00:00<00:01, 514MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  17% 168M/1.00G [00:00<00:01, 503MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  22% 220M/1.00G [00:00<00:01, 507MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  27% 273M/1.00G [00:00<00:01, 510MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  32% 325M/1.00G [00:00<00:01, 511MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  38% 377M/1.00G [00:00<00:01, 368MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  43% 430M/1.00G [00:01<00:02, 281MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  47% 472M/1.00G [00:01<00:02, 242MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  50% 503M/1.00G [00:01<00:02, 224MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  53% 535M/1.00G [00:01<00:02, 213MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  56% 566M/1.00G [00:01<00:02, 210MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  61% 608M/1.00G [00:02<00:01, 244MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  66% 661M/1.00G [00:02<00:01, 291MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  71% 713M/1.00G [00:02<00:00, 330MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  76% 765M/1.00G [00:02<00:00, 369MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  81% 818M/1.00G [00:02<00:00, 382MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  87% 870M/1.00G [00:02<00:00, 409MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  92% 923M/1.00G [00:02<00:00, 437MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 1.00G/1.00G [00:02<00:00, 351MB/s]\n","Downloading shards:  86% 24/28 [01:06<00:11,  2.84s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/896M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   6% 52.4M/896M [00:00<00:01, 460MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  12% 105M/896M [00:00<00:01, 450MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  18% 157M/896M [00:00<00:01, 476MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  25% 220M/896M [00:00<00:01, 501MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  32% 283M/896M [00:00<00:01, 513MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  39% 346M/896M [00:00<00:01, 522MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  46% 409M/896M [00:00<00:00, 528MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  53% 472M/896M [00:00<00:00, 526MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  60% 535M/896M [00:01<00:00, 528MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  67% 598M/896M [00:01<00:00, 530MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  74% 661M/896M [00:01<00:00, 528MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  81% 724M/896M [00:01<00:00, 532MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  88% 786M/896M [00:01<00:00, 533MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 896M/896M [00:01<00:00, 520MB/s]\n","Downloading shards:  89% 25/28 [01:08<00:07,  2.58s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/1.00G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   2% 21.0M/1.00G [00:00<00:07, 125MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   6% 62.9M/1.00G [00:00<00:03, 238MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  13% 126M/1.00G [00:00<00:02, 360MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  19% 189M/1.00G [00:00<00:01, 424MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  25% 252M/1.00G [00:00<00:01, 463MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  30% 304M/1.00G [00:00<00:01, 373MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  34% 346M/1.00G [00:01<00:02, 283MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  39% 388M/1.00G [00:01<00:02, 229MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  42% 419M/1.00G [00:01<00:03, 193MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  45% 451M/1.00G [00:01<00:03, 170MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  47% 472M/1.00G [00:01<00:03, 170MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  50% 503M/1.00G [00:02<00:02, 185MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  53% 535M/1.00G [00:02<00:02, 207MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  56% 566M/1.00G [00:02<00:01, 227MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  61% 608M/1.00G [00:02<00:01, 259MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  66% 661M/1.00G [00:02<00:01, 313MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  72% 724M/1.00G [00:02<00:00, 376MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  78% 786M/1.00G [00:02<00:00, 420MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  83% 839M/1.00G [00:03<00:00, 289MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  88% 881M/1.00G [00:03<00:00, 298MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  92% 923M/1.00G [00:03<00:00, 321MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  96% 965M/1.00G [00:03<00:00, 313MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 1.00G/1.00G [00:03<00:00, 275MB/s]\n","Downloading shards:  93% 26/28 [01:12<00:05,  2.99s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/896M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:   6% 52.4M/896M [00:00<00:01, 478MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  12% 105M/896M [00:00<00:01, 490MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  18% 157M/896M [00:00<00:01, 499MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  23% 210M/896M [00:00<00:01, 506MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  29% 262M/896M [00:00<00:01, 503MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  35% 315M/896M [00:00<00:01, 365MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  40% 357M/896M [00:00<00:01, 312MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  44% 398M/896M [00:01<00:01, 292MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  49% 440M/896M [00:01<00:01, 283MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  53% 472M/896M [00:01<00:01, 278MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  56% 503M/896M [00:01<00:01, 273MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  60% 535M/896M [00:01<00:01, 271MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  63% 566M/896M [00:01<00:01, 268MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  67% 598M/896M [00:01<00:01, 267MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  70% 629M/896M [00:01<00:01, 263MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  74% 661M/896M [00:02<00:00, 255MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  77% 692M/896M [00:02<00:00, 250MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  81% 724M/896M [00:02<00:00, 242MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  84% 755M/896M [00:02<00:00, 233MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  88% 786M/896M [00:02<00:00, 223MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  91% 818M/896M [00:02<00:00, 211MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  95% 849M/896M [00:03<00:00, 200MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  97% 870M/896M [00:03<00:00, 194MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 896M/896M [00:03<00:00, 267MB/s]\n","Downloading shards:  96% 27/28 [01:16<00:03,  3.18s/it]\n","Downloading (…)of-00028.safetensors:   0% 0.00/518M [00:00<?, ?B/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  10% 52.4M/518M [00:00<00:00, 478MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  20% 105M/518M [00:00<00:00, 497MB/s] \u001b[A\n","Downloading (…)of-00028.safetensors:  30% 157M/518M [00:00<00:00, 503MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  41% 210M/518M [00:00<00:00, 458MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  51% 262M/518M [00:00<00:00, 421MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  61% 315M/518M [00:00<00:00, 387MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  69% 357M/518M [00:00<00:00, 374MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  77% 398M/518M [00:00<00:00, 372MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors:  87% 451M/518M [00:01<00:00, 401MB/s]\u001b[A\n","Downloading (…)of-00028.safetensors: 100% 518M/518M [00:01<00:00, 420MB/s]\n","Downloading shards: 100% 28/28 [01:18<00:00,  2.79s/it]\n","Loading checkpoint shards: 100% 28/28 [00:12<00:00,  2.16it/s]\n","Downloading (…)neration_config.json: 100% 111/111 [00:00<00:00, 359kB/s]\n",">> Training arguments:\n","TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=True,\n","bf16_full_eval=True,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=False,\n","eval_accumulation_steps=1,\n","eval_delay=0,\n","eval_steps=48,\n","evaluation_strategy=steps,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=2,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=1e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=./checkpoints/8k-8bit-colab_20230907-060202/runs/Sep07_06-04-15_2a1cc4df82d2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=1,\n","optim=paged_adamw_8bit,\n","optim_args=None,\n","output_dir=./checkpoints/8k-8bit-colab_20230907-060202,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=16,\n","per_device_train_batch_size=8,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['wandb'],\n","resume_from_checkpoint=None,\n","run_name=./checkpoints/8k-8bit-colab_20230907-060202,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=48,\n","save_strategy=steps,\n","save_total_limit=5,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=1000,\n","weight_decay=0.0,\n",")\n","  0% 0/487 [00:00<?, ?it/s]You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","{'loss': 2.6834, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.02}\n","{'loss': 2.702, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.04}\n","{'loss': 2.7, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.06}\n","{'loss': 2.7015, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.08}\n"," 10% 48/487 [20:38<3:14:34, 26.59s/it]\n","  0% 0/13 [00:00<?, ?it/s]\u001b[A\n"," 15% 2/13 [00:03<00:19,  1.75s/it]\u001b[A\n"," 23% 3/13 [00:07<00:28,  2.82s/it]\u001b[A\n"," 31% 4/13 [00:12<00:30,  3.38s/it]\u001b[A\n"," 38% 5/13 [00:15<00:26,  3.28s/it]\u001b[A\n"," 46% 6/13 [00:19<00:24,  3.46s/it]\u001b[A\n"," 54% 7/13 [00:22<00:20,  3.49s/it]\u001b[A\n"," 62% 8/13 [00:26<00:18,  3.74s/it]\u001b[A\n"," 69% 9/13 [00:29<00:14,  3.50s/it]\u001b[A\n"," 77% 10/13 [00:33<00:10,  3.45s/it]\u001b[A\n"," 85% 11/13 [00:36<00:06,  3.26s/it]\u001b[A\n"," 92% 12/13 [00:40<00:03,  3.50s/it]\u001b[A\n","100% 13/13 [00:42<00:00,  3.09s/it]\u001b[A\n","{'eval_loss': 2.6972687244415283, 'eval_runtime': 46.2622, 'eval_samples_per_second': 4.323, 'eval_steps_per_second': 0.281, 'epoch': 0.1}\n","\n"," 10% 48/487 [21:24<3:14:34, 26.59s/it]\n","                                   \u001b[A/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","{'loss': 2.6943, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.1}\n","{'loss': 2.6905, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.12}\n","{'loss': 2.7254, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.14}\n","{'loss': 2.7051, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.16}\n","{'loss': 2.7582, 'learning_rate': 9.000000000000001e-07, 'epoch': 0.18}\n"," 20% 96/487 [41:45<2:44:31, 25.25s/it]\n","  0% 0/13 [00:00<?, ?it/s]\u001b[A\n"," 15% 2/13 [00:03<00:19,  1.76s/it]\u001b[A\n"," 23% 3/13 [00:07<00:28,  2.83s/it]\u001b[A\n"," 31% 4/13 [00:12<00:30,  3.38s/it]\u001b[A\n"," 38% 5/13 [00:15<00:26,  3.28s/it]\u001b[A\n"," 46% 6/13 [00:19<00:24,  3.46s/it]\u001b[A\n"," 54% 7/13 [00:22<00:20,  3.49s/it]\u001b[A\n"," 62% 8/13 [00:26<00:18,  3.74s/it]\u001b[A\n"," 69% 9/13 [00:29<00:14,  3.51s/it]\u001b[A\n"," 77% 10/13 [00:33<00:10,  3.45s/it]\u001b[A\n"," 85% 11/13 [00:36<00:06,  3.26s/it]\u001b[A\n"," 92% 12/13 [00:40<00:03,  3.50s/it]\u001b[A\n","100% 13/13 [00:42<00:00,  3.09s/it]\u001b[A\n","{'eval_loss': 2.692730188369751, 'eval_runtime': 46.0557, 'eval_samples_per_second': 4.343, 'eval_steps_per_second': 0.282, 'epoch': 0.2}\n","\n"," 20% 96/487 [42:31<2:44:31, 25.25s/it]\n","                                   \u001b[A/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","{'loss': 2.694, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.21}\n","{'loss': 2.6861, 'learning_rate': 1.1e-06, 'epoch': 0.23}\n","{'loss': 2.7217, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.25}\n","{'loss': 2.6974, 'learning_rate': 1.3e-06, 'epoch': 0.27}\n","{'loss': 2.7237, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.29}\n"," 30% 144/487 [1:02:59<2:25:53, 25.52s/it]\n","  0% 0/13 [00:00<?, ?it/s]\u001b[A\n"," 15% 2/13 [00:03<00:19,  1.75s/it]\u001b[A\n"," 23% 3/13 [00:07<00:28,  2.83s/it]\u001b[A\n"," 31% 4/13 [00:12<00:30,  3.38s/it]\u001b[A\n"," 38% 5/13 [00:15<00:26,  3.28s/it]\u001b[A\n"," 46% 6/13 [00:19<00:24,  3.46s/it]\u001b[A\n"," 54% 7/13 [00:22<00:20,  3.49s/it]\u001b[A\n"," 62% 8/13 [00:26<00:18,  3.74s/it]\u001b[A\n"," 69% 9/13 [00:29<00:14,  3.51s/it]\u001b[A\n"," 77% 10/13 [00:33<00:10,  3.45s/it]\u001b[A\n"," 85% 11/13 [00:36<00:06,  3.26s/it]\u001b[A\n"," 92% 12/13 [00:40<00:03,  3.49s/it]\u001b[A\n","100% 13/13 [00:42<00:00,  3.08s/it]\u001b[A\n","{'eval_loss': 2.679899215698242, 'eval_runtime': 46.0153, 'eval_samples_per_second': 4.346, 'eval_steps_per_second': 0.283, 'epoch': 0.3}\n","\n"," 30% 144/487 [1:03:45<2:25:53, 25.52s/it]\n","                                   \u001b[A/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","{'loss': 2.7129, 'learning_rate': 1.5e-06, 'epoch': 0.31}\n","{'loss': 2.6801, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.33}\n","{'loss': 2.6715, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.35}\n","{'loss': 2.6845, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.37}\n","{'loss': 2.6541, 'learning_rate': 1.9000000000000002e-06, 'epoch': 0.39}\n"," 39% 192/487 [1:24:13<2:05:11, 25.46s/it]\n","  0% 0/13 [00:00<?, ?it/s]\u001b[A\n"," 15% 2/13 [00:03<00:19,  1.76s/it]\u001b[A\n"," 23% 3/13 [00:07<00:28,  2.83s/it]\u001b[A\n"," 31% 4/13 [00:12<00:30,  3.38s/it]\u001b[A\n"," 38% 5/13 [00:15<00:26,  3.28s/it]\u001b[A\n"," 46% 6/13 [00:19<00:24,  3.46s/it]\u001b[A\n"," 54% 7/13 [00:22<00:20,  3.49s/it]\u001b[A\n"," 62% 8/13 [00:26<00:18,  3.74s/it]\u001b[A\n"," 69% 9/13 [00:29<00:14,  3.50s/it]\u001b[A\n"," 77% 10/13 [00:33<00:10,  3.45s/it]\u001b[A\n"," 85% 11/13 [00:36<00:06,  3.26s/it]\u001b[A\n"," 92% 12/13 [00:40<00:03,  3.49s/it]\u001b[A\n","100% 13/13 [00:42<00:00,  3.08s/it]\u001b[A\n","{'eval_loss': 2.6495749950408936, 'eval_runtime': 46.0062, 'eval_samples_per_second': 4.347, 'eval_steps_per_second': 0.283, 'epoch': 0.39}\n","\n"," 39% 192/487 [1:24:59<2:05:11, 25.46s/it]\n","                                   \u001b[A/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","{'loss': 2.6692, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.41}\n","{'loss': 2.6507, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.43}\n","{'loss': 2.6333, 'learning_rate': 2.2e-06, 'epoch': 0.45}\n","{'loss': 2.65, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.47}\n","{'loss': 2.5966, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.49}\n"," 49% 240/487 [1:45:31<1:50:08, 26.76s/it]\n","  0% 0/13 [00:00<?, ?it/s]\u001b[A\n"," 15% 2/13 [00:03<00:19,  1.76s/it]\u001b[A\n"," 23% 3/13 [00:07<00:28,  2.83s/it]\u001b[A\n"," 31% 4/13 [00:12<00:30,  3.38s/it]\u001b[A\n"," 38% 5/13 [00:15<00:26,  3.28s/it]\u001b[A\n"," 46% 6/13 [00:19<00:24,  3.46s/it]\u001b[A\n"," 54% 7/13 [00:22<00:20,  3.49s/it]\u001b[A\n"," 62% 8/13 [00:26<00:18,  3.74s/it]\u001b[A\n"," 69% 9/13 [00:29<00:14,  3.51s/it]\u001b[A\n"," 77% 10/13 [00:33<00:10,  3.45s/it]\u001b[A\n"," 85% 11/13 [00:36<00:06,  3.26s/it]\u001b[A\n"," 92% 12/13 [00:40<00:03,  3.50s/it]\u001b[A\n","100% 13/13 [00:42<00:00,  3.09s/it]\u001b[A\n","{'eval_loss': 2.5809450149536133, 'eval_runtime': 46.0449, 'eval_samples_per_second': 4.344, 'eval_steps_per_second': 0.282, 'epoch': 0.49}\n","\n"," 49% 240/487 [1:46:17<1:50:08, 26.76s/it]\n","                                   \u001b[A/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","{'loss': 2.5638, 'learning_rate': 2.5e-06, 'epoch': 0.51}\n","{'loss': 2.562, 'learning_rate': 2.6e-06, 'epoch': 0.53}\n","{'loss': 2.5295, 'learning_rate': 2.7000000000000004e-06, 'epoch': 0.55}\n","{'loss': 2.4922, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.57}\n"," 59% 288/487 [2:06:42<1:20:40, 24.32s/it]\n","  0% 0/13 [00:00<?, ?it/s]\u001b[A\n"," 15% 2/13 [00:03<00:19,  1.75s/it]\u001b[A\n"," 23% 3/13 [00:07<00:28,  2.83s/it]\u001b[A\n"," 31% 4/13 [00:12<00:30,  3.38s/it]\u001b[A\n"," 38% 5/13 [00:15<00:26,  3.28s/it]\u001b[A\n"," 46% 6/13 [00:19<00:24,  3.46s/it]\u001b[A\n"," 54% 7/13 [00:22<00:20,  3.49s/it]\u001b[A\n"," 62% 8/13 [00:26<00:18,  3.74s/it]\u001b[A\n"," 69% 9/13 [00:29<00:14,  3.51s/it]\u001b[A\n"," 77% 10/13 [00:33<00:10,  3.45s/it]\u001b[A\n"," 85% 11/13 [00:36<00:06,  3.26s/it]\u001b[A\n"," 92% 12/13 [00:40<00:03,  3.49s/it]\u001b[A\n","100% 13/13 [00:42<00:00,  3.09s/it]\u001b[A\n","{'eval_loss': 2.4494574069976807, 'eval_runtime': 46.0214, 'eval_samples_per_second': 4.346, 'eval_steps_per_second': 0.282, 'epoch': 0.59}\n","\n"," 59% 288/487 [2:07:28<1:20:40, 24.32s/it]\n","                                   \u001b[A/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","{'loss': 2.5008, 'learning_rate': 2.9e-06, 'epoch': 0.59}\n","{'loss': 2.445, 'learning_rate': 3e-06, 'epoch': 0.62}\n","{'loss': 2.3853, 'learning_rate': 3.1000000000000004e-06, 'epoch': 0.64}\n","{'loss': 2.3763, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.66}\n","{'loss': 2.3424, 'learning_rate': 3.3000000000000006e-06, 'epoch': 0.68}\n"," 69% 336/487 [2:27:41<1:02:39, 24.90s/it]\n","  0% 0/13 [00:00<?, ?it/s]\u001b[A\n"," 15% 2/13 [00:03<00:19,  1.75s/it]\u001b[A\n"," 23% 3/13 [00:07<00:28,  2.82s/it]\u001b[A\n"," 31% 4/13 [00:12<00:30,  3.37s/it]\u001b[A\n"," 38% 5/13 [00:15<00:26,  3.27s/it]\u001b[A\n"," 46% 6/13 [00:19<00:24,  3.46s/it]\u001b[A\n"," 54% 7/13 [00:22<00:20,  3.49s/it]\u001b[A\n"," 62% 8/13 [00:26<00:18,  3.73s/it]\u001b[A\n"," 69% 9/13 [00:29<00:14,  3.50s/it]\u001b[A\n"," 77% 10/13 [00:33<00:10,  3.44s/it]\u001b[A\n"," 85% 11/13 [00:35<00:06,  3.26s/it]\u001b[A\n"," 92% 12/13 [00:40<00:03,  3.49s/it]\u001b[A\n","100% 13/13 [00:42<00:00,  3.08s/it]\u001b[A\n","{'eval_loss': 2.2781763076782227, 'eval_runtime': 45.9653, 'eval_samples_per_second': 4.351, 'eval_steps_per_second': 0.283, 'epoch': 0.69}\n","\n"," 69% 336/487 [2:28:26<1:02:39, 24.90s/it]\n","                                   \u001b[A/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","{'loss': 2.2979, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.7}\n","{'loss': 2.2699, 'learning_rate': 3.5e-06, 'epoch': 0.72}\n","{'loss': 2.2617, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.74}\n","{'loss': 2.2035, 'learning_rate': 3.7e-06, 'epoch': 0.76}\n","{'loss': 2.1213, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.78}\n"," 79% 384/487 [2:48:47<43:30, 25.35s/it]\n","  0% 0/13 [00:00<?, ?it/s]\u001b[A\n"," 15% 2/13 [00:03<00:19,  1.75s/it]\u001b[A\n"," 23% 3/13 [00:07<00:28,  2.82s/it]\u001b[A\n"," 31% 4/13 [00:12<00:30,  3.37s/it]\u001b[A\n"," 38% 5/13 [00:15<00:26,  3.28s/it]\u001b[A\n"," 46% 6/13 [00:19<00:24,  3.47s/it]\u001b[A\n"," 54% 7/13 [00:22<00:20,  3.50s/it]\u001b[A\n"," 62% 8/13 [00:26<00:18,  3.74s/it]\u001b[A\n"," 69% 9/13 [00:29<00:14,  3.51s/it]\u001b[A\n"," 77% 10/13 [00:33<00:10,  3.46s/it]\u001b[A\n"," 85% 11/13 [00:36<00:06,  3.27s/it]\u001b[A\n"," 92% 12/13 [00:40<00:03,  3.50s/it]\u001b[A\n","100% 13/13 [00:42<00:00,  3.09s/it]\u001b[A\n","{'eval_loss': 2.128342866897583, 'eval_runtime': 46.0435, 'eval_samples_per_second': 4.344, 'eval_steps_per_second': 0.282, 'epoch': 0.79}\n","\n"," 79% 384/487 [2:49:33<43:30, 25.35s/it]\n","                                   \u001b[A/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","{'loss': 2.1378, 'learning_rate': 3.900000000000001e-06, 'epoch': 0.8}\n","{'loss': 2.0921, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.82}\n","{'loss': 2.098, 'learning_rate': 4.1e-06, 'epoch': 0.84}\n","{'loss': 2.0852, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.86}\n","{'loss': 2.0262, 'learning_rate': 4.3e-06, 'epoch': 0.88}\n"," 89% 432/487 [3:10:11<25:44, 28.09s/it]\n","  0% 0/13 [00:00<?, ?it/s]\u001b[A\n"," 15% 2/13 [00:03<00:19,  1.76s/it]\u001b[A\n"," 23% 3/13 [00:07<00:28,  2.83s/it]\u001b[A\n"," 31% 4/13 [00:12<00:30,  3.39s/it]\u001b[A\n"," 38% 5/13 [00:15<00:26,  3.28s/it]\u001b[A\n"," 46% 6/13 [00:19<00:24,  3.46s/it]\u001b[A\n"," 54% 7/13 [00:22<00:20,  3.49s/it]\u001b[A\n"," 62% 8/13 [00:26<00:18,  3.74s/it]\u001b[A\n"," 69% 9/13 [00:29<00:14,  3.50s/it]\u001b[A\n"," 77% 10/13 [00:33<00:10,  3.45s/it]\u001b[A\n"," 85% 11/13 [00:36<00:06,  3.26s/it]\u001b[A\n"," 92% 12/13 [00:40<00:03,  3.49s/it]\u001b[A\n","100% 13/13 [00:42<00:00,  3.08s/it]\u001b[A\n","{'eval_loss': 2.0293707847595215, 'eval_runtime': 46.0151, 'eval_samples_per_second': 4.346, 'eval_steps_per_second': 0.283, 'epoch': 0.89}\n","\n"," 89% 432/487 [3:10:57<25:44, 28.09s/it]\n","                                   \u001b[A/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","{'loss': 2.0271, 'learning_rate': 4.4e-06, 'epoch': 0.9}\n","{'loss': 2.0106, 'learning_rate': 4.5e-06, 'epoch': 0.92}\n","{'loss': 1.9983, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.94}\n","{'loss': 1.994, 'learning_rate': 4.7e-06, 'epoch': 0.96}\n","{'loss': 1.9777, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.98}\n"," 99% 480/487 [3:31:16<02:58, 25.57s/it]\n","  0% 0/13 [00:00<?, ?it/s]\u001b[A\n"," 15% 2/13 [00:03<00:19,  1.75s/it]\u001b[A\n"," 23% 3/13 [00:07<00:28,  2.82s/it]\u001b[A\n"," 31% 4/13 [00:12<00:30,  3.39s/it]\u001b[A\n"," 38% 5/13 [00:15<00:26,  3.28s/it]\u001b[A\n"," 46% 6/13 [00:19<00:24,  3.46s/it]\u001b[A\n"," 54% 7/13 [00:22<00:20,  3.49s/it]\u001b[A\n"," 62% 8/13 [00:26<00:18,  3.74s/it]\u001b[A\n"," 69% 9/13 [00:29<00:14,  3.50s/it]\u001b[A\n"," 77% 10/13 [00:33<00:10,  3.45s/it]\u001b[A\n"," 85% 11/13 [00:36<00:06,  3.26s/it]\u001b[A\n"," 92% 12/13 [00:40<00:03,  3.50s/it]\u001b[A\n","100% 13/13 [00:42<00:00,  3.09s/it]\u001b[A\n","{'eval_loss': 1.9767365455627441, 'eval_runtime': 46.0261, 'eval_samples_per_second': 4.345, 'eval_steps_per_second': 0.282, 'epoch': 0.98}\n","\n"," 99% 480/487 [3:32:02<02:58, 25.57s/it]\n","                                   \u001b[A/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","{'train_runtime': 12898.4808, 'train_samples_per_second': 0.605, 'train_steps_per_second': 0.038, 'train_loss': 2.4577198929365656, 'epoch': 1.0}\n","100% 487/487 [3:34:58<00:00, 26.49s/it]\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ████▇▆▄▂▂▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime █▃▂▂▃▂▁▃▂▂\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▁▆▇▇▆▇█▆▇▆\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▁▅██▅▅█▅█▅\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss ▇▇▇▇▇███▇▇▇██▇▇▇▇▇▇▇▆▆▆▆▆▅▅▄▄▄▃▂▂▂▂▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 1.97674\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 46.0261\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 4.345\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 0.282\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 1.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 487\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 1.9777\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 4.825974003690701e+17\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 2.45772\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 12898.4808\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 0.605\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.038\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcelestial-cosmos-13\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/kimkihyun/Meeting-Log-Summ/runs/s1s9ybzt\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230907_060201-s1s9ybzt/logs\u001b[0m\n"]}],"source":["!python finetune.py --input_fn ./data/aug.jsonl --model_name 8k-8bit-colab --use_8bit --batch_size_per_device 8 --gradient_accumulation_steps 2 --num_train_epochs 3"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP0ENulo2InGmyE1OTB7DN5","gpuType":"A100","machine_shape":"hm","mount_file_id":"1r0CPX0iG8h0O8Xei9VEljrGnlem5s9aa","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
